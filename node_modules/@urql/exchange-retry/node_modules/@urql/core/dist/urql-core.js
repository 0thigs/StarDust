Object.defineProperty(exports, '__esModule', {
  value: true
});
var graphql = require('graphql');
var fetchSource = require('./52541c06.js');
var wonka = require('wonka');
var collectTypes = (obj, types) => {
  if (Array.isArray(obj)) {
    for (var item of obj) {
      collectTypes(item, types);
    }
  } else if (typeof obj === 'object' && obj !== null) {
    for (var key in obj) {
      if (key === '__typename' && typeof obj[key] === 'string') {
        types.add(obj[key]);
      } else {
        collectTypes(obj[key], types);
      }
    }
  }
  return types;
};
var collectTypesFromResponse = response => [...collectTypes(response, new Set())];
var formatNode = node => {
  if (!node.selectionSet) return node;
  for (var selection of node.selectionSet.selections) {
    if (selection.kind === graphql.Kind.FIELD && selection.name.value === '__typename' && !selection.alias) return node;
  }
  return {
    ...node,
    selectionSet: {
      ...node.selectionSet,
      selections: [...node.selectionSet.selections, {
        kind: graphql.Kind.FIELD,
        name: {
          kind: graphql.Kind.NAME,
          value: '__typename'
        }
      }]
    }
  };
};
var formattedDocs = new Map();
var formatDocument = node => {
  var query = fetchSource.keyDocument(node);
  var result = formattedDocs.get(query.__key);
  if (!result) {
    result = graphql.visit(query, {
      Field: formatNode,
      InlineFragment: formatNode
    });
    // Ensure that the hash of the resulting document won't suddenly change
    // we are marking __key as non-enumerable so when external exchanges use visit
    // to manipulate a document we won't restore the previous query due to the __key
    // property.
    Object.defineProperty(result, '__key', {
      value: query.__key,
      enumerable: false
    });
    formattedDocs.set(query.__key, result);
  }
  return result;
};
var maskTypename = (data, isRoot) => {
  if (!data || typeof data !== 'object') {
    return data;
  } else if (Array.isArray(data)) {
    return data.map(d => maskTypename(d));
  } else if (data && typeof data === 'object' && (isRoot || '__typename' in data)) {
    var acc = {};
    for (var key in data) {
      if (key === '__typename') {
        Object.defineProperty(acc, '__typename', {
          enumerable: false,
          value: data.__typename
        });
      } else {
        acc[key] = maskTypename(data[key]);
      }
    }
    return acc;
  } else {
    return data;
  }
};
function withPromise(source$) {
  source$.toPromise = () => {
    return new Promise(resolve => {
      var subscription = wonka.subscribe(result => {
        if (!result.stale && !result.hasNext) {
          Promise.resolve().then(() => {
            subscription.unsubscribe();
            resolve(result);
          });
        }
      })(source$);
    });
  };
  return source$;
}
function makeOperation(kind, request, context) {
  if (!context) context = request.context;
  return {
    key: request.key,
    query: request.query,
    variables: request.variables,
    kind,
    context
  };
}
/** Spreads the provided metadata to the source operation's meta property in context.  */
var addMetadata = (operation, meta) => {
  return makeOperation(operation.kind, operation, {
    ...operation.context,
    meta: {
      ...operation.context.meta,
      ...meta
    }
  });
};
var noop = () => {
  /* noop */
};

/* eslint-disable prefer-rest-params */
var applyDefinitions = (fragmentNames, target, source) => {
  for (var definition of source) {
    if (definition.kind === graphql.Kind.FRAGMENT_DEFINITION) {
      var name = definition.name.value;
      var value = fetchSource.stringifyDocument(definition);
      // Fragments will be deduplicated according to this Map
      if (!fragmentNames.has(name)) {
        fragmentNames.set(name, value);
        target.push(definition);
      } else if (process.env.NODE_ENV !== 'production' && fragmentNames.get(name) !== value) {
        // Fragments with the same names is expected to have the same contents
        console.warn('[WARNING: Duplicate Fragment] A fragment with name `' + name + '` already exists in this document.\n' + 'While fragment names may not be unique across your source, each name must be unique per document.');
      }
    } else {
      target.push(definition);
    }
  }
};
function gql( /* arguments */
) {
  var fragmentNames = new Map();
  var definitions = [];
  var interpolations = [];
  // Apply the entire tagged template body's definitions
  var body = Array.isArray(arguments[0]) ? arguments[0][0] : arguments[0] || '';
  for (var i = 1; i < arguments.length; i++) {
    var value = arguments[i];
    if (value && value.definitions) {
      interpolations.push(...value.definitions);
    } else {
      body += value;
    }
    body += arguments[0][i];
  }
  // Apply the tag's body definitions
  applyDefinitions(fragmentNames, definitions, fetchSource.keyDocument(body).definitions);
  // Copy over each interpolated document's definitions
  applyDefinitions(fragmentNames, definitions, interpolations);
  return fetchSource.keyDocument({
    kind: graphql.Kind.DOCUMENT,
    definitions
  });
}

/* eslint-disable @typescript-eslint/no-use-before-define */
var shouldSkip = ({
  kind
}) => kind !== 'mutation' && kind !== 'query';
var cacheExchange = ({
  forward,
  client,
  dispatchDebug
}) => {
  var resultCache = new Map();
  var operationCache = new Map();
  // Adds unique typenames to query (for invalidating cache entries)
  var mapTypeNames = operation => {
    var formattedOperation = makeOperation(operation.kind, operation);
    formattedOperation.query = formatDocument(operation.query);
    return formattedOperation;
  };
  var isOperationCached = operation => {
    var {
      key,
      kind,
      context: {
        requestPolicy
      }
    } = operation;
    return kind === 'query' && requestPolicy !== 'network-only' && (requestPolicy === 'cache-only' || resultCache.has(key));
  };
  return ops$ => {
    var sharedOps$ = wonka.share(ops$);
    var cachedOps$ = wonka.map(operation => {
      var cachedResult = resultCache.get(operation.key);
      process.env.NODE_ENV !== 'production' ? dispatchDebug({
        operation,
        ...(cachedResult ? {
          type: 'cacheHit',
          message: 'The result was successfully retried from the cache'
        } : {
          type: 'cacheMiss',
          message: 'The result could not be retrieved from the cache'
        }),
        "source": "cacheExchange"
      }) : undefined;
      var result = {
        ...cachedResult,
        operation: addMetadata(operation, {
          cacheOutcome: cachedResult ? 'hit' : 'miss'
        })
      };
      if (operation.context.requestPolicy === 'cache-and-network') {
        result.stale = true;
        reexecuteOperation(client, operation);
      }
      return result;
    })(wonka.filter(op => !shouldSkip(op) && isOperationCached(op))(sharedOps$));
    var forwardedOps$ = wonka.tap(response => {
      var {
        operation
      } = response;
      if (!operation) return;
      var typenames = collectTypesFromResponse(response.data).concat(operation.context.additionalTypenames || []);
      // Invalidates the cache given a mutation's response
      if (response.operation.kind === 'mutation') {
        var pendingOperations = new Set();
        process.env.NODE_ENV !== 'production' ? dispatchDebug({
          type: 'cacheInvalidation',
          message: `The following typenames have been invalidated: ${typenames}`,
          operation,
          data: {
            typenames,
            response
          },
          "source": "cacheExchange"
        }) : undefined;
        for (var i = 0; i < typenames.length; i++) {
          var typeName = typenames[i];
          var operations = operationCache.get(typeName);
          if (!operations) operationCache.set(typeName, operations = new Set());
          for (var key of operations.values()) {
            pendingOperations.add(key);
          }
          operations.clear();
        }
        for (var _key of pendingOperations.values()) {
          if (resultCache.has(_key)) {
            operation = resultCache.get(_key).operation;
            resultCache.delete(_key);
            reexecuteOperation(client, operation);
          }
        }
      } else if (operation.kind === 'query' && response.data) {
        resultCache.set(operation.key, response);
        for (var _i = 0; _i < typenames.length; _i++) {
          var _typeName = typenames[_i];
          var _operations = operationCache.get(_typeName);
          if (!_operations) operationCache.set(_typeName, _operations = new Set());
          _operations.add(operation.key);
        }
      }
    })(forward(wonka.filter(op => op.kind !== 'query' || op.context.requestPolicy !== 'cache-only')(wonka.map(op => addMetadata(op, {
      cacheOutcome: 'miss'
    }))(wonka.merge([wonka.map(mapTypeNames)(wonka.filter(op => !shouldSkip(op) && !isOperationCached(op))(sharedOps$)), wonka.filter(op => shouldSkip(op))(sharedOps$)])))));
    return wonka.merge([cachedOps$, forwardedOps$]);
  };
};
// Reexecutes a given operation with the default requestPolicy
var reexecuteOperation = (client, operation) => {
  return client.reexecuteOperation(makeOperation(operation.kind, operation, {
    ...operation.context,
    requestPolicy: 'network-only'
  }));
};

/** Serialize an OperationResult to plain JSON */
var serializeResult = ({
  hasNext,
  data,
  extensions,
  error
}, includeExtensions) => {
  var result = {};
  if (data !== undefined) result.data = JSON.stringify(data);
  if (includeExtensions && extensions !== undefined) {
    result.extensions = JSON.stringify(extensions);
  }
  if (hasNext) result.hasNext = true;
  if (error) {
    result.error = {
      graphQLErrors: error.graphQLErrors.map(error => {
        if (!error.path && !error.extensions) return error.message;
        return {
          message: error.message,
          path: error.path,
          extensions: error.extensions
        };
      })
    };
    if (error.networkError) {
      result.error.networkError = '' + error.networkError;
    }
  }
  return result;
};
/** Deserialize plain JSON to an OperationResult */
var deserializeResult = (operation, result, includeExtensions) => ({
  operation,
  data: result.data ? JSON.parse(result.data) : undefined,
  extensions: includeExtensions && result.extensions ? JSON.parse(result.extensions) : undefined,
  error: result.error ? new fetchSource.CombinedError({
    networkError: result.error.networkError ? new Error(result.error.networkError) : undefined,
    graphQLErrors: result.error.graphQLErrors
  }) : undefined,
  hasNext: result.hasNext
});
var revalidated = new Set();
/** The ssrExchange can be created to capture data during SSR and also to rehydrate it on the client */
var ssrExchange = (params = {}) => {
  var staleWhileRevalidate = !!params.staleWhileRevalidate;
  var includeExtensions = !!params.includeExtensions;
  var data = {};
  // On the client-side, we delete results from the cache as they're resolved
  // this is delayed so that concurrent queries don't delete each other's data
  var invalidateQueue = [];
  var invalidate = result => {
    invalidateQueue.push(result.operation.key);
    if (invalidateQueue.length === 1) {
      Promise.resolve().then(() => {
        var key;
        while (key = invalidateQueue.shift()) {
          data[key] = null;
        }
      });
    }
  };
  // The SSR Exchange is a temporary cache that can populate results into data for suspense
  // On the client it can be used to retrieve these temporary results from a rehydrated cache
  var ssr = ({
    client,
    forward
  }) => ops$ => {
    // params.isClient tells us whether we're on the client-side
    // By default we assume that we're on the client if suspense-mode is disabled
    var isClient = params && typeof params.isClient === 'boolean' ? !!params.isClient : !client.suspense;
    var sharedOps$ = wonka.share(ops$);
    var forwardedOps$ = forward(wonka.filter(operation => !data[operation.key] || !!data[operation.key].hasNext || operation.context.requestPolicy === 'network-only')(sharedOps$));
    // NOTE: Since below we might delete the cached entry after accessing
    // it once, cachedOps$ needs to be merged after forwardedOps$
    var cachedOps$ = wonka.map(op => {
      var serialized = data[op.key];
      var cachedResult = deserializeResult(op, serialized, includeExtensions);
      if (staleWhileRevalidate && !revalidated.has(op.key)) {
        cachedResult.stale = true;
        revalidated.add(op.key);
        reexecuteOperation(client, op);
      }
      var result = {
        ...cachedResult,
        operation: addMetadata(op, {
          cacheOutcome: 'hit'
        })
      };
      return result;
    })(wonka.filter(operation => !!data[operation.key] && operation.context.requestPolicy !== 'network-only')(sharedOps$));
    if (!isClient) {
      // On the server we cache results in the cache as they're resolved
      forwardedOps$ = wonka.tap(result => {
        var {
          operation
        } = result;
        if (operation.kind !== 'mutation') {
          var serialized = serializeResult(result, includeExtensions);
          data[operation.key] = serialized;
        }
      })(forwardedOps$);
    } else {
      // On the client we delete results from the cache as they're resolved
      cachedOps$ = wonka.tap(invalidate)(cachedOps$);
    }
    return wonka.merge([forwardedOps$, cachedOps$]);
  };
  ssr.restoreData = restore => {
    for (var key in restore) {
      // We only restore data that hasn't been previously invalidated
      if (data[key] !== null) {
        data[key] = restore[key];
      }
    }
  };
  ssr.extractData = () => {
    var result = {};
    for (var key in data) {
      if (data[key] != null) result[key] = data[key];
    }
    return result;
  };
  if (params && params.initialState) {
    ssr.restoreData(params.initialState);
  }
  return ssr;
};
var subscriptionExchange = ({
  forwardSubscription,
  enableAllOperations,
  isSubscriptionOperation
}) => ({
  client,
  forward
}) => {
  var createSubscriptionSource = operation => {
    // This excludes the query's name as a field although subscription-transport-ws does accept it since it's optional
    var observableish = forwardSubscription({
      key: operation.key.toString(36),
      query: fetchSource.stringifyDocument(operation.query),
      variables: operation.variables,
      context: {
        ...operation.context
      }
    });
    return wonka.make(({
      next,
      complete
    }) => {
      var isComplete = false;
      var sub;
      Promise.resolve().then(() => {
        if (isComplete) return;
        sub = observableish.subscribe({
          next: result => next(fetchSource.makeResult(operation, result)),
          error: err => next(fetchSource.makeErrorResult(operation, err)),
          complete: () => {
            if (!isComplete) {
              isComplete = true;
              if (operation.kind === 'subscription') {
                client.reexecuteOperation(makeOperation('teardown', operation, operation.context));
              }
              complete();
            }
          }
        });
      });
      return () => {
        isComplete = true;
        if (sub) sub.unsubscribe();
      };
    });
  };
  var isSubscriptionOperationFn = isSubscriptionOperation || (operation => {
    var {
      kind
    } = operation;
    return kind === 'subscription' || !!enableAllOperations && (kind === 'query' || kind === 'mutation');
  });
  return ops$ => {
    var sharedOps$ = wonka.share(ops$);
    var subscriptionResults$ = wonka.mergeMap(operation => {
      var {
        key
      } = operation;
      var teardown$ = wonka.filter(op => op.kind === 'teardown' && op.key === key)(sharedOps$);
      return wonka.takeUntil(teardown$)(createSubscriptionSource(operation));
    })(wonka.filter(isSubscriptionOperationFn)(sharedOps$));
    var forward$ = forward(wonka.filter(op => !isSubscriptionOperationFn(op))(sharedOps$));
    return wonka.merge([subscriptionResults$, forward$]);
  };
};
var debugExchange = ({
  forward
}) => {
  if (process.env.NODE_ENV === 'production') {
    return ops$ => forward(ops$);
  } else {
    return ops$ => wonka.tap(result =>
    // eslint-disable-next-line no-console
    console.log('[Exchange debug]: Completed operation: ', result))(forward(
    // eslint-disable-next-line no-console
    wonka.tap(op => console.log('[Exchange debug]: Incoming operation: ', op))(ops$)));
  }
};

/** A default exchange for debouncing GraphQL requests. */
var dedupExchange = ({
  forward,
  dispatchDebug
}) => {
  var inFlightKeys = new Set();
  var filterIncomingOperation = operation => {
    var {
      key,
      kind
    } = operation;
    if (kind === 'teardown' || kind === 'mutation') {
      inFlightKeys.delete(key);
      return true;
    }
    var isInFlight = inFlightKeys.has(key);
    inFlightKeys.add(key);
    if (isInFlight) {
      process.env.NODE_ENV !== 'production' ? dispatchDebug({
        type: 'dedup',
        message: 'An operation has been deduped.',
        operation,
        "source": "dedupExchange"
      }) : undefined;
    }
    return !isInFlight;
  };
  var afterOperationResult = ({
    operation,
    hasNext
  }) => {
    if (!hasNext) {
      inFlightKeys.delete(operation.key);
    }
  };
  return ops$ => {
    var forward$ = wonka.filter(filterIncomingOperation)(ops$);
    return wonka.tap(afterOperationResult)(forward(forward$));
  };
};

/* eslint-disable @typescript-eslint/no-use-before-define */
/** A default exchange for fetching GraphQL requests. */
var fetchExchange = ({
  forward,
  dispatchDebug
}) => {
  return ops$ => {
    var sharedOps$ = wonka.share(ops$);
    var fetchResults$ = wonka.mergeMap(operation => {
      var {
        key
      } = operation;
      var body = fetchSource.makeFetchBody(operation);
      var url = fetchSource.makeFetchURL(operation, body);
      var fetchOptions = fetchSource.makeFetchOptions(operation, body);
      process.env.NODE_ENV !== 'production' ? dispatchDebug({
        type: 'fetchRequest',
        message: 'A fetch request is being executed.',
        operation,
        data: {
          url,
          fetchOptions
        },
        "source": "fetchExchange"
      }) : undefined;
      var source = wonka.takeUntil(wonka.filter(op => op.kind === 'teardown' && op.key === key)(sharedOps$))(fetchSource.makeFetchSource(operation, url, fetchOptions));
      if (process.env.NODE_ENV !== 'production') {
        return wonka.onPush(result => {
          var error = !result.data ? result.error : undefined;
          process.env.NODE_ENV !== 'production' ? dispatchDebug({
            type: error ? 'fetchError' : 'fetchSuccess',
            message: `A ${error ? 'failed' : 'successful'} fetch response has been returned.`,
            operation,
            data: {
              url,
              fetchOptions,
              value: error || result
            },
            "source": "fetchExchange"
          }) : undefined;
        })(source);
      }
      return source;
    })(wonka.filter(operation => {
      return operation.kind === 'query' || operation.kind === 'mutation';
    })(sharedOps$));
    var forward$ = forward(wonka.filter(operation => {
      return operation.kind !== 'query' && operation.kind !== 'mutation';
    })(sharedOps$));
    return wonka.merge([fetchResults$, forward$]);
  };
};

/** This is always the last exchange in the chain; No operation should ever reach it */
var fallbackExchange = ({
  dispatchDebug
}) => ops$ => /* All operations that skipped through the entire exchange chain should be filtered from the output */
wonka.filter(() => false)(wonka.tap(operation => {
  if (operation.kind !== 'teardown' && process.env.NODE_ENV !== 'production') {
    var message = `No exchange has handled operations of kind "${operation.kind}". Check whether you've added an exchange responsible for these operations.`;
    process.env.NODE_ENV !== 'production' ? dispatchDebug({
      type: 'fallbackCatch',
      message,
      operation,
      "source": "fallbackExchange"
    }) : undefined;
    console.warn(message);
  }
})(ops$));
var fallbackExchangeIO = fallbackExchange({
  dispatchDebug: noop
});

/** This composes an array of Exchanges into a single ExchangeIO function */
var composeExchanges = exchanges => ({
  client,
  forward,
  dispatchDebug
}) => exchanges.reduceRight((forward, exchange) => exchange({
  client,
  forward,
  dispatchDebug(event) {
    process.env.NODE_ENV !== 'production' ? dispatchDebug({
      timestamp: Date.now(),
      source: exchange.name,
      ...event
    }) : undefined;
  }
}), forward);
var mapExchange = ({
  onOperation,
  onResult,
  onError
}) => {
  return ({
    forward
  }) => ops$ => {
    return wonka.mergeMap(result => {
      if (onError && result.error) onError(result.error, result.operation);
      var newResult = onResult && onResult(result) || result;
      return 'then' in newResult ? wonka.fromPromise(newResult) : wonka.fromValue(newResult);
    })(forward(wonka.mergeMap(operation => {
      var newOperation = onOperation && onOperation(operation) || operation;
      return 'then' in newOperation ? wonka.fromPromise(newOperation) : wonka.fromValue(newOperation);
    })(ops$)));
  };
};
var defaultExchanges = [dedupExchange, cacheExchange, fetchExchange];

/* eslint-disable @typescript-eslint/no-use-before-define */
var Client = function Client(opts) {
  if (process.env.NODE_ENV !== 'production' && !opts.url) {
    throw new Error('You are creating an urql-client without a url.');
  }
  var ids = 0;
  var replays = new Map();
  var active = new Map();
  var queue = [];
  var baseOpts = {
    url: opts.url,
    fetchOptions: opts.fetchOptions,
    fetch: opts.fetch,
    preferGetMethod: !!opts.preferGetMethod,
    requestPolicy: opts.requestPolicy || 'cache-first'
  };
  // This subject forms the input of operations; executeOperation may be
  // called to dispatch a new operation on the subject
  var {
    source: operations$,
    next: nextOperation
  } = wonka.makeSubject();
  // We define a queued dispatcher on the subject, which empties the queue when it's
  // activated to allow `reexecuteOperation` to be trampoline-scheduled
  var isOperationBatchActive = false;
  function dispatchOperation(operation) {
    if (operation) nextOperation(operation);
    if (!isOperationBatchActive) {
      isOperationBatchActive = true;
      while (isOperationBatchActive && (operation = queue.shift())) {
        nextOperation(operation);
      }
      isOperationBatchActive = false;
    }
  }
  /** Defines how result streams are created */
  var makeResultSource = operation => {
    var result$ = wonka.filter(res => {
      return res.operation.kind === operation.kind && res.operation.key === operation.key && (!res.operation.context._instance || res.operation.context._instance === operation.context._instance);
    })(results$);
    // Mask typename properties if the option for it is turned on
    if (opts.maskTypename) {
      result$ = wonka.map(res => ({
        ...res,
        data: maskTypename(res.data, true)
      }))(result$);
    }
    // A mutation is always limited to just a single result and is never shared
    if (operation.kind === 'mutation') {
      return wonka.take(1)(wonka.onStart(() => nextOperation(operation))(result$));
    }
    var source = wonka.share(wonka.onEnd(() => {
      // Delete the active operation handle
      replays.delete(operation.key);
      active.delete(operation.key);
      // Delete all queued up operations of the same key on end
      for (var i = queue.length - 1; i >= 0; i--) {
        if (queue[i].key === operation.key) queue.splice(i, 1);
      }
      // Dispatch a teardown signal for the stopped operation
      nextOperation(makeOperation('teardown', operation, operation.context));
    })(wonka.onPush(result => {
      replays.set(operation.key, result);
    })(wonka.switchMap(result => {
      if (operation.kind !== 'query' || result.stale) {
        return wonka.fromValue(result);
      }
      return wonka.merge([wonka.fromValue(result),
      // Mark a result as stale when a new operation is sent for it
      wonka.map(() => ({
        ...result,
        stale: true
      }))(wonka.take(1)(wonka.filter(op => op.kind === 'query' && op.key === operation.key && op.context.requestPolicy !== 'cache-only')(operations$)))]);
    })(
    // End the results stream when an active teardown event is sent
    wonka.takeUntil(wonka.filter(op => op.kind === 'teardown' && op.key === operation.key)(operations$))(result$)))));
    return source;
  };
  var instance = this instanceof Client ? this : Object.create(Client.prototype);
  var client = Object.assign(instance, {
    suspense: !!opts.suspense,
    operations$,
    reexecuteOperation(operation) {
      // Reexecute operation only if any subscribers are still subscribed to the
      // operation's exchange results
      if (operation.kind === 'mutation' || active.has(operation.key)) {
        queue.push(operation);
        Promise.resolve().then(dispatchOperation);
      }
    },
    createRequestOperation(kind, request, opts) {
      if (!opts) opts = {};
      var requestOperationType = fetchSource.getOperationType(request.query);
      if (process.env.NODE_ENV !== 'production' && kind !== 'teardown' && requestOperationType !== kind) {
        throw new Error(`Expected operation of type "${kind}" but found "${requestOperationType}"`);
      }
      return makeOperation(kind, request, {
        _instance: kind === 'mutation' ? ids = ids + 1 | 0 : undefined,
        ...baseOpts,
        ...opts,
        requestPolicy: opts.requestPolicy || baseOpts.requestPolicy,
        suspense: opts.suspense || opts.suspense !== false && client.suspense
      });
    },
    executeRequestOperation(operation) {
      if (operation.kind === 'mutation') {
        return makeResultSource(operation);
      }
      return wonka.make(observer => {
        var source = active.get(operation.key);
        if (!source) {
          active.set(operation.key, source = makeResultSource(operation));
        }
        var isNetworkOperation = operation.context.requestPolicy === 'cache-and-network' || operation.context.requestPolicy === 'network-only';
        return wonka.subscribe(observer.next)(wonka.onEnd(() => {
          isOperationBatchActive = false;
          observer.complete();
        })(wonka.onStart(() => {
          var prevReplay = replays.get(operation.key);
          if (operation.kind === 'subscription') {
            return dispatchOperation(operation);
          } else if (isNetworkOperation) {
            dispatchOperation(operation);
          }
          if (prevReplay != null && prevReplay === replays.get(operation.key)) {
            observer.next(isNetworkOperation ? {
              ...prevReplay,
              stale: true
            } : prevReplay);
          } else if (!isNetworkOperation) {
            dispatchOperation(operation);
          }
        })(source))).unsubscribe;
      });
    },
    executeQuery(query, opts) {
      var operation = client.createRequestOperation('query', query, opts);
      return client.executeRequestOperation(operation);
    },
    executeSubscription(query, opts) {
      var operation = client.createRequestOperation('subscription', query, opts);
      return client.executeRequestOperation(operation);
    },
    executeMutation(query, opts) {
      var operation = client.createRequestOperation('mutation', query, opts);
      return client.executeRequestOperation(operation);
    },
    query(query, variables, context) {
      if (!context || typeof context.suspense !== 'boolean') {
        context = {
          ...context,
          suspense: false
        };
      }
      return withPromise(client.executeQuery(fetchSource.createRequest(query, variables), context));
    },
    readQuery(query, variables, context) {
      var result = null;
      wonka.subscribe(res => {
        result = res;
      })(client.query(query, variables, context)).unsubscribe();
      return result;
    },
    subscription(query, variables, context) {
      return client.executeSubscription(fetchSource.createRequest(query, variables), context);
    },
    mutation(query, variables, context) {
      return withPromise(client.executeMutation(fetchSource.createRequest(query, variables), context));
    }
  });
  var dispatchDebug = noop;
  if (process.env.NODE_ENV !== 'production') {
    var {
      next,
      source
    } = wonka.makeSubject();
    client.subscribeToDebugTarget = onEvent => wonka.subscribe(onEvent)(source);
    dispatchDebug = next;
  }
  var exchanges = opts.exchanges !== undefined ? opts.exchanges : defaultExchanges;
  // All exchange are composed into a single one and are called using the constructed client
  // and the fallback exchange stream
  var composedExchange = composeExchanges(exchanges);
  // All exchanges receive inputs using which they can forward operations to the next exchange
  // and receive a stream of results in return, access the client, or dispatch debugging events
  // All operations then run through the Exchange IOs in a pipeline-like fashion
  var results$ = wonka.share(composedExchange({
    client,
    dispatchDebug,
    forward: fallbackExchange({
      dispatchDebug
    })
  })(operations$));
  // Prevent the `results$` exchange pipeline from being closed by active
  // cancellations cascading up from components
  wonka.publish(results$);
  return client;
};
var createClient = Client;
exports.CombinedError = fetchSource.CombinedError;
exports.createRequest = fetchSource.createRequest;
exports.getOperationName = fetchSource.getOperationName;
exports.makeErrorResult = fetchSource.makeErrorResult;
exports.makeResult = fetchSource.makeResult;
exports.mergeResultPatch = fetchSource.mergeResultPatch;
exports.stringifyVariables = fetchSource.stringifyVariables;
exports.Client = Client;
exports.cacheExchange = cacheExchange;
exports.composeExchanges = composeExchanges;
exports.createClient = createClient;
exports.debugExchange = debugExchange;
exports.dedupExchange = dedupExchange;
exports.defaultExchanges = defaultExchanges;
exports.errorExchange = mapExchange;
exports.fallbackExchangeIO = fallbackExchangeIO;
exports.fetchExchange = fetchExchange;
exports.formatDocument = formatDocument;
exports.gql = gql;
exports.makeOperation = makeOperation;
exports.mapExchange = mapExchange;
exports.maskTypename = maskTypename;
exports.ssrExchange = ssrExchange;
exports.subscriptionExchange = subscriptionExchange;
//# sourceMappingURL=urql-core.js.map
